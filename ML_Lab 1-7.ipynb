{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"eNwYuDBaRFYX"},"outputs":[],"source":["import numpy as np\n","import pandas as pd"]},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount(\"/content/drive\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"8l9pehKFSG31","outputId":"69755081-b0ee-403f-d69a-df7bb8bd59a3"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"code","source":["fs=pd.read_csv(\"/content/drive/My Drive/Find-S.csv\")"],"metadata":{"id":"TgMNQY9043-i"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["r=len(fs)\n","c=len(fs.columns)-1\n","print(r,c)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Vh46oJfR5BmQ","outputId":"f2ff7208-8bf3-4d2a-d9b5-1569593c9eff"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["4 6\n"]}]},{"cell_type":"markdown","source":["# **Find - S    4/4/2023**"],"metadata":{"id":"DETAEQRIlcfV"}},{"cell_type":"code","source":["# 1.\tImplement and demonstrate the FIND-S algorithm to finding the most specific hypothesis\n","#  based on a given set of data samples. Read the training data from a .CSV file.\n","\n","\n","h=[None]*c\n","print('h0 :',h)\n","for i in range(r):\n","  if fs.loc[i]['EnjoySport']=='Yes':\n","    for j in range(c):\n","      if h[j]==None:\n","        h[j]=fs.loc[i][j]\n","      elif h[j]!=fs.loc[i][j]:\n","        h[j]='?'\n","\n","  print('h'+str(i+1),':',h)\n"],"metadata":{"id":"3gHc8IKNUNfg","colab":{"base_uri":"https://localhost:8080/"},"outputId":"c7a9a39c-9129-4529-f379-04a373cd8353"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["h0 : [None, None, None, None, None, None]\n","h1 : ['Sunny', 'Warm', 'Normal', 'Strong', 'Warm', 'Same']\n","h2 : ['Sunny', 'Warm', '?', 'Strong', 'Warm', 'Same']\n","h3 : ['Sunny', 'Warm', '?', 'Strong', 'Warm', 'Same']\n","h4 : ['Sunny', 'Warm', '?', 'Strong', '?', '?']\n"]}]},{"cell_type":"markdown","source":["# **Candidate Elimination   4/4/2023**"],"metadata":{"id":"q8SPvCPKi86N"}},{"cell_type":"code","source":["# 2.\tFor a given set of training data examples stored in a .CSV file, implement and demonstrate the Candidate-Elimination\n","#  algorithm to output a description of the set of all hypotheses consistent with the training examples.\n","\n","s=[None]*c\n","g_=['?']*c\n","g=[g_]\n","print('s0 :',s)\n","print('g0 :',g)\n","\n","def removeFrom(g,d):\n","  i=0\n","  while i<len(g):\n","    k=g[i]\n","    f=0\n","    for j in range(c):\n","      if k[j]!='?':\n","        if k[j]!=d[j]:\n","          g.remove(k)\n","          f=1\n","          break\n","    if f==0: i+=1\n","\n","\n","def generalize(s,d):\n","  for j in range(c):\n","      if s[j]==None:\n","        s[j]=d[j]\n","      elif s[j]!=d[j]:\n","        s[j]='?'\n","\n","\n","\n","def inconsistent(k,d):\n","  for j in range(c):\n","    if k[j]!='?':\n","      if k[j]!=d[j]:\n","        return 0\n","  return 1\n","\n","\n","def specialize(g,d):\n","  i=0\n","  m=[]\n","  while i<len(g):\n","    k=g[i]\n","    f=0\n","    if inconsistent(k,d):\n","      for j in range(c):\n","        p=k.copy()\n","        if p[j]=='?' and s[j]!='?' and  s[j]!=d[j]:\n","          p[j]=s[j]\n","          m.append(p)\n","      f=1\n","      g.remove(k)\n","    if f==0: i+=1\n","  g.extend(m)\n","  g=np.unique(g,axis=0)\n","\n","\n","for i in range(r):\n","  if fs.loc[i]['EnjoySport']=='Yes':\n","    removeFrom(g,fs.loc[i])\n","    generalize(s,fs.loc[i])\n","  else:\n","    specialize(g,fs.loc[i])\n","\n","  print('s'+str(i+1),':',s)\n","  print('g'+str(i+1),':',g)\n","\n","print('Learned Version Space Combinations:')\n","\n","v=[]\n","for k in g:\n","  f=0\n","  p=[]\n","  for j in range(c):\n","    if k[j]!='?' and k[j]==s[j]:\n","      p.append(j)\n","    elif k[j]!='?' and k[j]!=s[j]:\n","      f=1\n","      break\n","\n","  if f==0:\n","    for j in range(c):\n","      q=k.copy()\n","      if j not in p and s[j]!='?':\n","        q[j]=s[j]\n","        v.append(q)\n","\n","v=np.unique(v,axis=0)\n","print(v)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"BgRGh3BSi60O","outputId":"f13f0750-ce3e-4bb1-9675-02414c1b16d8"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["s0 : [None, None, None, None, None, None]\n","g0 : [['?', '?', '?', '?', '?', '?']]\n","s1 : ['Sunny', 'Warm', 'Normal', 'Strong', 'Warm', 'Same']\n","g1 : [['?', '?', '?', '?', '?', '?']]\n","s2 : ['Sunny', 'Warm', '?', 'Strong', 'Warm', 'Same']\n","g2 : [['?', '?', '?', '?', '?', '?']]\n","s3 : ['Sunny', 'Warm', '?', 'Strong', 'Warm', 'Same']\n","g3 : [['Sunny', '?', '?', '?', '?', '?'], ['?', 'Warm', '?', '?', '?', '?'], ['?', '?', '?', '?', '?', 'Same']]\n","s4 : ['Sunny', 'Warm', '?', 'Strong', '?', '?']\n","g4 : [['Sunny', '?', '?', '?', '?', '?'], ['?', 'Warm', '?', '?', '?', '?']]\n","Learned Version Space Combinations:\n","[['?' 'Warm' '?' 'Strong' '?' '?']\n"," ['Sunny' '?' '?' 'Strong' '?' '?']\n"," ['Sunny' 'Warm' '?' '?' '?' '?']]\n"]}]},{"cell_type":"markdown","source":["# naive bayes 11/04/2023"],"metadata":{"id":"YJMEGcLFRYuy"}},{"cell_type":"code","source":["# 3.\tWrite a program to implement the naÃ¯ve Bayesian classifier for a sample training data set stored as a .CSV file.\n","# Compute the accuracy of the classifier, considering few test data sets.\n","\n","import numpy as np\n","import pandas as pd\n","\n","from google.colab import drive\n","drive.mount(\"/content/drive\")\n","\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"7s4JbdqSRWTi","outputId":"c9c5ad09-fd08-497d-9d8f-ad0efc5615e6"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"code","source":["t=pd.read_csv('/content/drive/My Drive/Play_Tennis.csv')\n"],"metadata":{"id":"k-wPJIeiYmiR"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["t"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":488},"id":"pI7ia4gKYxsc","outputId":"2b2de7b4-29b9-4c9b-f817-d0fc342cbaed"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["     Outlook Temperature Humidity  Windy Class\n","0      sunny         hot     high  False     N\n","1      sunny         hot     high   True     N\n","2   overcast         hot     high  False     P\n","3       rain        mild     high  False     P\n","4       rain        cool   normal  False     P\n","5       rain        cool   normal   True     N\n","6   overcast        cool   normal   True     P\n","7      sunny        mild     high  False     N\n","8      sunny        cold   normal  False     P\n","9       rain        mild   normal  False     P\n","10     sunny        mild   normal   True     P\n","11  overcast        mild     high   True     P\n","12  overcast         hot   normal  False     P\n","13      rain        mild     high   True     N"],"text/html":["\n","  <div id=\"df-894c10f1-4322-4bad-b45c-0eed81baa540\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Outlook</th>\n","      <th>Temperature</th>\n","      <th>Humidity</th>\n","      <th>Windy</th>\n","      <th>Class</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>sunny</td>\n","      <td>hot</td>\n","      <td>high</td>\n","      <td>False</td>\n","      <td>N</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>sunny</td>\n","      <td>hot</td>\n","      <td>high</td>\n","      <td>True</td>\n","      <td>N</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>overcast</td>\n","      <td>hot</td>\n","      <td>high</td>\n","      <td>False</td>\n","      <td>P</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>rain</td>\n","      <td>mild</td>\n","      <td>high</td>\n","      <td>False</td>\n","      <td>P</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>rain</td>\n","      <td>cool</td>\n","      <td>normal</td>\n","      <td>False</td>\n","      <td>P</td>\n","    </tr>\n","    <tr>\n","      <th>5</th>\n","      <td>rain</td>\n","      <td>cool</td>\n","      <td>normal</td>\n","      <td>True</td>\n","      <td>N</td>\n","    </tr>\n","    <tr>\n","      <th>6</th>\n","      <td>overcast</td>\n","      <td>cool</td>\n","      <td>normal</td>\n","      <td>True</td>\n","      <td>P</td>\n","    </tr>\n","    <tr>\n","      <th>7</th>\n","      <td>sunny</td>\n","      <td>mild</td>\n","      <td>high</td>\n","      <td>False</td>\n","      <td>N</td>\n","    </tr>\n","    <tr>\n","      <th>8</th>\n","      <td>sunny</td>\n","      <td>cold</td>\n","      <td>normal</td>\n","      <td>False</td>\n","      <td>P</td>\n","    </tr>\n","    <tr>\n","      <th>9</th>\n","      <td>rain</td>\n","      <td>mild</td>\n","      <td>normal</td>\n","      <td>False</td>\n","      <td>P</td>\n","    </tr>\n","    <tr>\n","      <th>10</th>\n","      <td>sunny</td>\n","      <td>mild</td>\n","      <td>normal</td>\n","      <td>True</td>\n","      <td>P</td>\n","    </tr>\n","    <tr>\n","      <th>11</th>\n","      <td>overcast</td>\n","      <td>mild</td>\n","      <td>high</td>\n","      <td>True</td>\n","      <td>P</td>\n","    </tr>\n","    <tr>\n","      <th>12</th>\n","      <td>overcast</td>\n","      <td>hot</td>\n","      <td>normal</td>\n","      <td>False</td>\n","      <td>P</td>\n","    </tr>\n","    <tr>\n","      <th>13</th>\n","      <td>rain</td>\n","      <td>mild</td>\n","      <td>high</td>\n","      <td>True</td>\n","      <td>N</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-894c10f1-4322-4bad-b45c-0eed81baa540')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-894c10f1-4322-4bad-b45c-0eed81baa540 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-894c10f1-4322-4bad-b45c-0eed81baa540');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{},"execution_count":70}]},{"cell_type":"code","source":["from sklearn.model_selection import train_test_split\n","x=t.drop('Class',axis=1)\n","y=t.Class\n","x_train,x_test,y_train,y_test=train_test_split(x,y,test_size=0.4,random_state=15)"],"metadata":{"id":"BIUoQUOjhp8l"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["c=len(x_train)\n","print('No. of rows in x_train =',c)\n","q=len(x_test)\n","print('No. of rows in x_test =',q)\n","k=len(x_train.columns)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"yRh55yieY0Bx","outputId":"2b8c555e-2992-4c55-d3f6-34298b0c603f"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["No. of rows in x_train = 8\n","No. of rows in x_test = 6\n"]}]},{"cell_type":"code","source":["x_train.index=range(c)\n","x_test.index=range(q)\n","y_train.index=range(c)\n","y_test.index=range(q)\n","print('Train data')\n","print(x_train)\n","print('\\nTest data')\n","print(x_test)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"zKPVuLKtySLV","outputId":"6e9ebd18-8cce-4699-8191-6d98392e19af"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Train data\n","    Outlook Temperature Humidity  Windy\n","0  overcast        mild     high   True\n","1      rain        mild     high  False\n","2     sunny        mild   normal   True\n","3     sunny         hot     high  False\n","4     sunny        mild     high  False\n","5  overcast         hot   normal  False\n","6      rain        cool   normal   True\n","7     sunny        cold   normal  False\n","\n","Test data\n","    Outlook Temperature Humidity  Windy\n","0      rain        mild     high   True\n","1  overcast         hot     high  False\n","2      rain        mild   normal  False\n","3      rain        cool   normal  False\n","4     sunny         hot     high   True\n","5  overcast        cool   normal   True\n"]}]},{"cell_type":"code","source":["c_n=len(y_train[y_train=='N'])\n","p_n=c_n/c\n","print('Probability of Negative class = ',p_n)\n","c_p=len(y_train[y_train=='P'])\n","p_p=c_p/c\n","print('Probability of Positive class = ',p_p)"],"metadata":{"id":"82abSUSzY8lJ","colab":{"base_uri":"https://localhost:8080/"},"outputId":"069bea08-d952-4aa8-c722-e4960aa03e30"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Probability of Negative class =  0.375\n","Probability of Positive class =  0.625\n"]}]},{"cell_type":"code","source":["d_p={}\n","d_n={}\n","x_train['Class']=y_train\n","col=x_train.columns\n","for i in range(k):\n","  l=x_train[col[i]].unique()\n","  for j in l:\n","    d_p[j]=len(x_train[(x_train[col[i]]==j) & (x_train.Class=='P')])/c_p\n","    d_n[j]=len(x_train[(x_train[col[i]]==j) & (x_train.Class=='N')])/c_n\n"],"metadata":{"id":"xQz7u8usZlH-"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# c_n=len(y_test[y_test=='N'])\n","# p_n=c_n/q\n","# print('Probability of Negative class for test data = %.3f'%(p_n))\n","# c_p=len(y_test[y_test=='P'])\n","# p_p=c_p/q\n","# print('Probability of Positive class for test data = %.3f'%(p_p))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"wuWqZuz6sA0o","outputId":"e43eb7c2-f5fe-4df0-805e-d2473b890aad"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Probability of Negative class for test data =  0.3333333333333333\n","Probability of Positive class for test data =  0.6666666666666666\n"]}]},{"cell_type":"code","source":["res=[]\n","p,n=1,1\n","for i in range(q):\n","  f=x_test.loc[i]\n","  for j in range(k):\n","    p=p*d_p[f[j]]\n","    n=n*d_n[f[j]]\n","  p=p*p_p\n","  n=n*p_n\n","  if p>=n:\n","    res.append('P')\n","  else:\n","    res.append('N')"],"metadata":{"id":"rnQb1k48rFuy"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["print('Predicted class labels =',res)\n","print('Actual class labels =\\n',y_test)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Qch7iDMy0W4R","outputId":"f70bc46c-8c4a-43f6-a572-401b25895ce7"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Predicted class labels = ['P', 'P', 'P', 'P', 'P', 'P']\n","Actual class labels =\n"," 0    N\n","1    P\n","2    P\n","3    P\n","4    N\n","5    P\n","Name: Class, dtype: object\n"]}]},{"cell_type":"code","source":["acc=0\n","for i in range(q):\n","  if res[i]==y_test[i]:\n","    acc=acc+1\n","\n","print('Accuracy = %.3f'%(acc/q))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"HI2MmAPUrs56","outputId":"915c8b43-d614-4dee-8e5e-4b5e717b68ca"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Accuracy = 0.667\n"]}]},{"cell_type":"markdown","source":["# Naive Bayes 18/04/2023"],"metadata":{"id":"W_ckbnYWULg-"}},{"cell_type":"code","source":["# 4.\tAssuming a set of documents that need to be classified, use the naÃ¯ve Bayesian classifier model to perform this task. Built-in Java classes /API can be used to write the program.\n","# Calculate the accuracy precision and recall for your data set.\n","\n","import numpy as np\n","import pandas as pd\n","\n","from google.colab import drive\n","drive.mount(\"/content/drive\")\n"],"metadata":{"id":"ty6EAzESUKvH","colab":{"base_uri":"https://localhost:8080/"},"outputId":"ecfa0ed3-aae7-415b-ea6c-57afe084763a"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"code","source":["data=pd.read_csv('/content/drive/My Drive/naivetext.csv')"],"metadata":{"id":"BWEL-XsBifSn"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["data['Text']=data['Text'].str.lower()"],"metadata":{"id":"tcvE5QSs3j4c"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from sklearn.model_selection import train_test_split\n","x=data\n","y=data.Class\n","t,test,y_train,y_test=train_test_split(x,y,test_size=0.4,random_state=15)"],"metadata":{"id":"hhvyO3qp1gS1"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["r=len(t)\n","c=len(t.columns)\n","print('No. of rows in train set :',r)\n","\n","r1=len(test)\n","test.index=range(r1)\n","print('No. of rows in test set:',r1)\n","\n","t.index,test.index,y_train.index,y_test.index=range(r),range(r1),range(r),range(r1)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"solAhqD1ipKM","outputId":"4758b024-18b3-4d5a-87a0-d454e9dd2e98"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["No. of rows in train set : 10\n","No. of rows in test set: 8\n"]}]},{"cell_type":"code","source":["vocab=[]\n","for i in range(r):\n","  vocab.extend(t['Text'][i].split())\n","\n","vocab=list(set(vocab))\n","l=len(vocab)\n","print('Vocabulary:',vocab)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"psAf3fC8itHF","outputId":"da4c2a23-a005-4aaf-ef34-426b9a3159a2"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Vocabulary: ['like', 'with', 'is', 'sworn', 'tomorrow', 'dance', 'i', 'the', 'good', 'great', 'am', 'locality', 'deal', 'tired', 'stuff', 'not', 'this', 'to', 'will', 'have', \"can't\", 'sandwich', 'restaurant', 'stay', 'juice', 'of', 'holiday', 'do', 'enemy', 'my', 'a', 'bad', 'fun', 'he', 'we', 'that', 'what', 'love', 'taste']\n"]}]},{"cell_type":"code","source":["c_p=len(t[t.Class=='pos'])\n","c_n=len(t[t.Class=='neg'])\n","p_p,p_n=c_p/r,c_n/r\n","print('Probability of positive texts = %.3f'%(p_p))\n","print('Probability of negative texts = %.3f'%(p_n))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"NoJWiktKkwqH","outputId":"11be50e6-da12-4d3f-f9b2-4e278f3415d3"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Probability of positive texts = 0.400\n","Probability of negative texts = 0.600\n"]}]},{"cell_type":"code","source":["d_p,d_n={},{}\n","for i in range(r):\n","  if t['Class'][i]=='pos':\n","    for j in t['Text'][i].split():\n","      d_p[j]=d_p.get(j,0)+1\n","  else:\n","    for j in t['Text'][i].split():\n","      d_n[j]=d_n.get(j,0)+1\n","\n","n1=sum(d_p.values())\n","n2=sum(d_n.values())\n","for i in vocab:\n","  d_p[i]=(d_p.get(i,0)+1)/(n1+l)\n","  d_n[i]=(d_n.get(i,0)+1)/(n2+l)\n","\n","\n","res=[]\n","for i in range(r1):\n","  p,n=1,1\n","  for j in test['Text'][i].split():\n","    if j in vocab:\n","      p=p*d_p[j]\n","      n=n*d_n[j]\n","\n","  p=p*p_p\n","  n=n*p_n\n","  if p>n:\n","    res.append('pos')\n","  else:\n","    res.append('neg')"],"metadata":{"id":"y3QoFPFtlqEJ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["print('Predicted class labels =',res)\n","print('Actual class labels =',list(test['Class']))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"SrpKH8VBsCOc","outputId":"01cdcc54-ac91-49e6-8e50-6360f21dfbe7"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Predicted class labels = ['pos', 'neg', 'neg', 'pos', 'neg', 'neg', 'neg', 'neg']\n","Actual class labels = ['pos', 'neg', 'pos', 'pos', 'neg', 'pos', 'neg', 'pos']\n"]}]},{"cell_type":"code","source":["tn,fn,tp,fp=0,0,0,0\n","for i in range(r1):\n","  if res[i]=='neg' and test['Class'][i]=='neg':\n","    tn=tn+1\n","  elif res[i]=='neg' and test['Class'][i]=='pos':\n","    fn=fn+1\n","  elif res[i]=='pos' and test['Class'][i]=='neg':\n","    fp=fp+1\n","  elif res[i]=='pos' and test['Class'][i]=='pos':\n","    tp=tp+1\n","\n","cfm=[[tn,fp],[fn,tp]]\n","print('Confusion Matrix:',cfm)\n","acc=(tp+tn)/(tp+tn+fp+fn)\n","precision=tp/(tp+fp)\n","recall=tp/(tp+fn)\n","\n","print('Accuracy = %.3f'%(acc))\n","print('Precision = %.3f'%(precision))\n","print('Recall = %.3f'%(recall))\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"eLc95HD72B6j","outputId":"d4e024e9-ed34-443d-a9a9-e93488a9ebcc"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Confusion Matrix: [[3, 0], [3, 2]]\n","Accuracy = 0.625\n","Precision = 1.000\n","Recall = 0.400\n"]}]},{"cell_type":"markdown","source":["# Bayesian Network 25/04/2023"],"metadata":{"id":"nssAz8955W6a"}},{"cell_type":"code","source":["# 5. Write a program to construct a Bayesian network considering medical data. Use this modelto demonstrate the diagnosis of\n","# heart patients using standard Heart Disease Data Set. You can use Java/Python ML library classes/API\n"],"metadata":{"id":"17UwICDt7AnV"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount(\"/content/drive\")"],"metadata":{"id":"1VYZDwqn60XI"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# pip install pgmpy"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ZQnjzGB18AcF","outputId":"8290499b-debb-4429-90ce-6503b4af3746"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting pgmpy\n","  Downloading pgmpy-0.1.22-py3-none-any.whl (1.9 MB)\n","\u001b[2K     \u001b[90mââââââââââââââââââââââââââââââââââââââââ\u001b[0m \u001b[32m1.9/1.9 MB\u001b[0m \u001b[31m20.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from pgmpy) (1.10.1)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from pgmpy) (4.65.0)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from pgmpy) (3.1)\n","Requirement already satisfied: pyparsing in /usr/local/lib/python3.10/dist-packages (from pgmpy) (3.0.9)\n","Requirement already satisfied: statsmodels in /usr/local/lib/python3.10/dist-packages (from pgmpy) (0.13.5)\n","Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from pgmpy) (1.2.0)\n","Requirement already satisfied: opt-einsum in /usr/local/lib/python3.10/dist-packages (from pgmpy) (3.3.0)\n","Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from pgmpy) (1.5.3)\n","Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from pgmpy) (1.2.2)\n","Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from pgmpy) (2.0.0+cu118)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from pgmpy) (1.22.4)\n","Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->pgmpy) (2022.7.1)\n","Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas->pgmpy) (2.8.2)\n","Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->pgmpy) (3.1.0)\n","Requirement already satisfied: patsy>=0.5.2 in /usr/local/lib/python3.10/dist-packages (from statsmodels->pgmpy) (0.5.3)\n","Requirement already satisfied: packaging>=21.3 in /usr/local/lib/python3.10/dist-packages (from statsmodels->pgmpy) (23.1)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch->pgmpy) (3.1.2)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch->pgmpy) (3.12.0)\n","Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch->pgmpy) (1.11.1)\n","Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.10/dist-packages (from torch->pgmpy) (2.0.0)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch->pgmpy) (4.5.0)\n","Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch->pgmpy) (3.25.2)\n","Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch->pgmpy) (16.0.2)\n","Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from patsy>=0.5.2->statsmodels->pgmpy) (1.16.0)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch->pgmpy) (2.1.2)\n","Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch->pgmpy) (1.3.0)\n","Installing collected packages: pgmpy\n","Successfully installed pgmpy-0.1.22\n"]}]},{"cell_type":"code","source":["import numpy as np\n","import pandas as pd\n","\n","from pgmpy.estimators import MaximumLikelihoodEstimator\n","from pgmpy.models import BayesianNetwork\n","from pgmpy.inference import VariableElimination\n","#read Cleveland Heart Disease data\n","heartDisease = pd.read_csv('/content/drive/My Drive/heart.csv')\n","heartDisease = heartDisease.replace('?',np.nan)\n","#display the data\n","print('Sample instances from the dataset are given below')\n","print(heartDisease.head())\n","\n","# display the Attributes names and datatyes\n","# print('\\n Attributes and datatypes')\n","# print(heartDisease.dtypes)\n","\n","#Creat Model- Bayesian Network\n","model = BayesianNetwork([('age','heartdisease'),('sex','heartdisease'),(\n","'exang','heartdisease'),('cp','heartdisease'),('heartdisease',\n","'restecg'),('heartdisease','chol')])\n","#Learning CPDs using Maximum Likelihood Estimators\n","print('\\n Learning CPD using Maximum likelihood estimators')\n","model.fit(heartDisease,estimator=MaximumLikelihoodEstimator)\n","# Inferencing with Bayesian Network\n","print('\\n Inferencing with Bayesian Network:')\n","HeartDiseasetest_infer = VariableElimination(model)\n","#computing the Probability of HeartDisease given restecg\n","print('\\n 1.Probability of HeartDisease given evidence=restecg :1')\n","q1=HeartDiseasetest_infer.query(variables=['heartdisease'],evidence={'restecg':1})\n","print(q1)\n","#computing the Probability of HeartDisease given cp\n","print('\\n 2.Probability of HeartDisease given evidence= cp:2 ')\n","q2=HeartDiseasetest_infer.query(variables=['heartdisease'],evidence={'cp':2})\n","print(q2)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"_8vNJz-s6REL","outputId":"de8f414a-6425-48df-bf60-837592b6b54e"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Sample instances from the dataset are given below\n","   age  sex  cp  trestbps  chol  fbs  restecg  thalach  exang  oldpeak  slope  \\\n","0   63    1   3       145   233    1        0      150      0      2.3      0   \n","1   37    1   2       130   250    0        1      187      0      3.5      0   \n","2   41    0   1       130   204    0        0      172      0      1.4      2   \n","3   56    1   1       120   236    0        1      178      0      0.8      2   \n","4   57    0   0       120   354    0        1      163      1      0.6      2   \n","\n","   ca  thal  heartdisease  \n","0   0     1             1  \n","1   0     2             1  \n","2   0     2             1  \n","3   0     2             1  \n","4   0     2             1  \n","\n"," Learning CPD using Maximum likelihood estimators\n","\n"," Inferencing with Bayesian Network:\n","\n"," 1.Probability of HeartDisease given evidence=restecg :1\n","+-----------------+---------------------+\n","| heartdisease    |   phi(heartdisease) |\n","+=================+=====================+\n","| heartdisease(0) |              0.4242 |\n","+-----------------+---------------------+\n","| heartdisease(1) |              0.5758 |\n","+-----------------+---------------------+\n","\n"," 2.Probability of HeartDisease given evidence= cp:2 \n","+-----------------+---------------------+\n","| heartdisease    |   phi(heartdisease) |\n","+=================+=====================+\n","| heartdisease(0) |              0.3755 |\n","+-----------------+---------------------+\n","| heartdisease(1) |              0.6245 |\n","+-----------------+---------------------+\n"]}]},{"cell_type":"markdown","source":["# Decision Tree\n","\n","\n"],"metadata":{"id":"yOOVHxq39dHm"}},{"cell_type":"code","source":["# 13/06/2023\n","# 6.\tWrite a program to demonstrate the working of the decision tree based ID3 algorithm.\n","# Use an appropriate data set for building the decision tree and apply this knowledge to classify a new sample.\n","\n","\n","from google.colab import drive\n","drive.mount(\"/content/drive\")"],"metadata":{"id":"LB-5gS7kkYaD","colab":{"base_uri":"https://localhost:8080/"},"outputId":"14c525d2-dd6f-4845-ea6f-2e5932a407dd"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"code","source":["#ID3 Algorithm\n","import math\n","import csv\n","def load_csv(filename):\n","    lines=csv.reader(open(filename,\"r\"));\n","    dataset = list(lines)\n","    headers = dataset.pop(0)\n","    return dataset,headers\n","\n","class Node:\n","    def __init__(self,attribute):\n","        self.attribute=attribute\n","        self.children=[]\n","        self.answer=\"\"\n","\n","def subtables(data,col,delete):\n","    dic={}\n","    coldata=[row[col] for row in data]\n","    attr=list(set(coldata))\n","\n","    counts=[0]*len(attr)\n","    r=len(data)\n","    c=len(data[0])\n","    for x in range(len(attr)):\n","        for y in range(r):\n","            if data[y][col]==attr[x]:\n","                counts[x]+=1\n","\n","    for x in range(len(attr)):\n","        dic[attr[x]]=[[0 for i in range(c)] for j in range(counts[x])]\n","        pos=0\n","        for y in range(r):\n","            if data[y][col]==attr[x]:\n","                if delete:\n","                    del data[y][col]\n","                dic[attr[x]][pos]=data[y]\n","                pos+=1\n","    return attr,dic\n","\n","def entropy(S):\n","    attr=list(set(S))\n","    if len(attr)==1:\n","        return 0\n","\n","    counts=[0,0]\n","    for i in range(2):\n","        counts[i]=sum([1 for x in S if attr[i]==x])/(len(S)*1.0)\n","\n","    sums=0\n","    for cnt in counts:\n","        sums+=-1*cnt*math.log(cnt,2)\n","    return sums\n","\n","def compute_gain(data,col):\n","    attr,dic = subtables(data,col,delete=False)\n","\n","    total_size=len(data)\n","    entropies=[0]*len(attr)\n","    ratio=[0]*len(attr)\n","\n","    total_entropy=entropy([row[-1] for row in data])\n","    for x in range(len(attr)):\n","        ratio[x]=len(dic[attr[x]])/(total_size*1.0)\n","        entropies[x]=entropy([row[-1] for row in dic[attr[x]]])\n","        total_entropy-=ratio[x]*entropies[x]\n","    return total_entropy\n","\n","def build_tree(data,features):\n","    lastcol=[row[-1] for row in data]\n","    if(len(set(lastcol)))==1:\n","        node=Node(\"\")\n","        node.answer=lastcol[0]\n","        return node\n","\n","    n=len(data[0])-1\n","    gains=[0]*n\n","    for col in range(n):\n","        gains[col]=compute_gain(data,col)\n","    split=gains.index(max(gains))\n","    node=Node(features[split])\n","    fea = features[:split]+features[split+1:]\n","\n","\n","    attr,dic=subtables(data,split,delete=True)\n","\n","    for x in range(len(attr)):\n","        child=build_tree(dic[attr[x]],fea)\n","        node.children.append((attr[x],child))\n","    return node\n","\n","def print_tree(node,level):\n","    if node.answer!=\"\":\n","        print(\"  \"*level,node.answer)\n","        return\n","\n","    print(\"  \"*level,node.attribute)\n","    for value,n in node.children:\n","        print(\"  \"*(level+1),value)\n","        print_tree(n,level+2)\n","\n","\n","def classify(node,x_test,features):\n","    if node.answer!=\"\":\n","        print(node.answer)\n","        return\n","    pos=features.index(node.attribute)\n","    for value, n in node.children:\n","        if x_test[pos]==value:\n","            classify(n,x_test,features)\n","\n","'''Main program'''\n","dataset,features=load_csv('/content/drive/My Drive/id3.csv')\n","node1=build_tree(dataset,features)\n","\n","print(\"The decision tree for the dataset using ID3 algorithm is\")\n","print_tree(node1,0)\n","testdata,features=load_csv('/content/drive/My Drive/id3_test.csv')\n","\n","for xtest in testdata:\n","    print(\"The test instance:\",xtest)\n","    print(\"The label for test instance:\",end=\"   \")\n","    classify(node1,xtest,features)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"9quvpYp-5-CL","outputId":"a1ff7348-3b82-4b5f-84ae-57679b7241a1"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["The decision tree for the dataset using ID3 algorithm is\n"," Outlook\n","   rain\n","     Wind\n","       weak\n","         yes\n","       strong\n","         no\n","   overcast\n","     yes\n","   sunny\n","     Humidity\n","       high\n","         no\n","       normal\n","         yes\n","The test instance: ['rain', 'cool', 'normal', 'strong']\n","The label for test instance:   no\n","The test instance: ['sunny', 'mild', 'normal', 'strong']\n","The label for test instance:   yes\n"]}]},{"cell_type":"code","source":["# import pandas as pd\n","# from sklearn.tree import DecisionTreeClassifier # Import Decision Tree Classifier\n","# from sklearn.model_selection import train_test_split # Import train_test_split function\n","# from sklearn import metrics #Import scikit-learn metrics module for accuracy calculation\n","\n","# col_names=['Outlook','Temperature','Humidity','Wind','PlayTennis']\n","# data = pd.read_csv(\"/content/drive/My Drive/id3.csv\", header=None, names=col_names)\n","# feature_cols = ['Outlook', 'Temperature', 'Humidity', 'Wind']\n","# X = data[feature_cols] # Features\n","# y = data.PlayTennis # Target variable\n","# X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=1)\n","\n","# # Create Decision Tree classifer object\n","# clf = DecisionTreeClassifier(criterion=\"entropy\")\n","\n","# # Train Decision Tree Classifer\n","# clf = clf.fit(X_train,y_train)\n","\n","# #Predict the response for test dataset\n","# y_pred = clf.predict(X_test)\n","# print(\"Accuracy:\",metrics.accuracy_score(y_test, y_pred))"],"metadata":{"id":"KmqXtQdAAWlI"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#7.\tBuild an Artificial Neural Network by implementing the Back propagation algorithm and test the same using appropriate data sets.\n","import numpy as np\n","X = np.array(([2, 9], [1, 5], [3, 6]), dtype=float) # two inputs [sleep,study]\n","y = np.array(([92], [86], [89]), dtype=float) # one output [Expected % in Exams]\n","X = X/np.amax(X,axis=0) # maximum of X array longitudinally\n","y = y/100\n","\n","#Sigmoid Function\n","def sigmoid (x):\n","    return 1/(1 + np.exp(-x))\n","\n","#Derivative of Sigmoid Function\n","def derivatives_sigmoid(x):\n","    return x * (1 - x)\n","\n","#Variable initialization\n","epoch=5000 #Setting training iterations\n","lr=0.1 #Setting learning rate\n","inputlayer_neurons = 2 #number of features in data set\n","hiddenlayer_neurons = 3 #number of hidden layers neurons\n","output_neurons = 1 #number of neurons at output layer\n","\n","#weight and bias initialization\n","wh=np.random.uniform(size=(inputlayer_neurons,hiddenlayer_neurons)) #weight of the link from input node to hidden node\n","bh=np.random.uniform(size=(1,hiddenlayer_neurons)) # bias of the link from input node to hidden node\n","wout=np.random.uniform(size=(hiddenlayer_neurons,output_neurons)) #weight of the link from hidden node to output node\n","bout=np.random.uniform(size=(1,output_neurons)) #bias of the link from hidden node to output node\n","\n","\n","#draws a random range of numbers uniformly of dim x*y\n","for i in range(epoch):\n","\n","#Forward Propogation\n","    hinp1=np.dot(X,wh)\n","    hinp=hinp1 + bh\n","    hlayer_act = sigmoid(hinp)\n","    outinp1=np.dot(hlayer_act,wout)\n","    outinp= outinp1+ bout\n","    output = sigmoid(outinp)\n","\n","#Backpropagation\n","    EO = y-output\n","    outgrad = derivatives_sigmoid(output)\n","    d_output = EO* outgrad\n","    EH = d_output.dot(wout.T)\n","\n","#how much hidden layer weights contributed to error\n","    hiddengrad = derivatives_sigmoid(hlayer_act)\n","    d_hiddenlayer = EH * hiddengrad\n","\n","# dotproduct of nextlayererror and currentlayerop\n","wout += hlayer_act.T.dot(d_output) *lr\n","wh += X.T.dot(d_hiddenlayer) *lr\n","\n","print(\"Input: \\n\" + str(X))\n","print(\"Actual Output: \\n\" + str(y))\n","print(\"Predicted Output: \\n\" ,output)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"wi8wLtlpNStk","outputId":"617ec990-821d-4bd3-c834-9bb0f60bc198"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Input: \n","[[0.66666667 1.        ]\n"," [0.33333333 0.55555556]\n"," [1.         0.66666667]]\n","Actual Output: \n","[[0.92]\n"," [0.86]\n"," [0.89]]\n","Predicted Output: \n"," [[0.75664002]\n"," [0.74431963]\n"," [0.75627592]]\n"]}]}]}